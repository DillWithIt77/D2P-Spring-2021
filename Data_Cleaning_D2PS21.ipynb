{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Data to Policy Spring 2021"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Weston Grewe and Angela Morrison\n",
    "\n",
    "University of Colorado Denver\n",
    "\n",
    "Math 7594 Integer Programming\n",
    "\n",
    "Instructor: Dr. Steffen Borgwardt"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Summary\n",
    "A college degree is becoming a necessary requirement of entering the middle class. A college education is also an excellent way to lift people out of poverty. Some high schools have high immediate college enrollments while others have low immediate college enrollments. For any one high school, it is nearly impossible to determine which factors contribute significantly to college enrollment. Often, it is a blend of many factors such as class size, proportion of low income students, teacher pay, number of AP classes offered, and many other factors. \n",
    "\n",
    "In this project, we create an interpretable optimal decision tree to understand which factors make the greatest impact. We will use data from Massachusetts' public schools in 2017 which can be found on Kaggle."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 240,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "from numpy import savetxt"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 187,
   "metadata": {},
   "outputs": [],
   "source": [
    "raw_data = pd.read_csv('MA_Public_Schools_2017.csv')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The dataset contains 302 fields for 1861 schools. This includes elementary, middle, and high schools as well as schools that serve many grade levels. We will begin by selecting only schools which serve senior high school students. A school which does not serve seniors cannot have immediate college enrollment. We will then select only fields which would be beneficial to this analysis. For example, the number of AP classes taken is relevant while the school's principal is not."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 189,
   "metadata": {},
   "outputs": [],
   "source": [
    "slice1 = raw_data[raw_data['12_Enrollment'] > 1];\n",
    "slice1.columns.tolist();"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Now, we must choose which columns to include in our analysis. It would also be interesting to study mutable and immutable factors in two different analyses to understand what changes. For instance, some factors may be most determining, e.g. poverty/wealth, but schools have no control over these factors. For a decision, schools can only be concerned with mutable factors, e.g. teacher pay, number of AP classes. \n",
    "\n",
    "Factors (in order of Col #)\n",
    "- School type (Public/Charter)\n",
    "- ZIP \n",
    "- District/District Code\n",
    "- Total Enrollment\n",
    "- First Lang Not English\n",
    "- English Lang Learner\n",
    "- Disability\n",
    "- High Need\n",
    "- Economically Disadvantaged\n",
    "- Race Makeup\n",
    "- Average Class Size\n",
    "- Average Salary\n",
    "- Average Expenditure per Pupil\n",
    "- % Graduated\n",
    "- % Dropped Out\n",
    "- AP Test takers\n",
    "- Number of Tests Taken\n",
    "- AP Score\n",
    "- Average SAT Math\n",
    "- Average SAT Reading\n",
    "- Average SAT Writing\n",
    "- 10th Grade MCAS (If used, filter for 10th graders)\n",
    "- Accountability Metrics"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Replace \"%\" symbols in column names to avoid possible errors in future column name calling."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 190,
   "metadata": {},
   "outputs": [],
   "source": [
    "slice1.columns = slice1.columns.str.replace('%', 'Percent');"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Take only columns with information we care about."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 191,
   "metadata": {},
   "outputs": [],
   "source": [
    ">>> important_cols = slice1[['Total # of Classes', 'TOTAL_Enrollment','Percent First Language Not English',\\\n",
    "                             'Average Class Size','Percent Attending College','AP_Test Takers',\\\n",
    "                             'AP_One Test', 'AP_Two Tests', 'AP_Three Tests','AP_Four Tests', 'AP_Five or More Tests',\\\n",
    "                             'SAT_Tests Taken']]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Get current shape of new dataframe and remove rows with any missing data and get shape of new dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 192,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(393, 12)\n",
      "(295, 12)\n"
     ]
    }
   ],
   "source": [
    "print(important_cols.shape)\n",
    "important_cols.isnull().sum().sum()\n",
    "clean_imp_cols = important_cols.dropna()\n",
    "print(clean_imp_cols.shape)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Print names of columns in cleaned dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 193,
   "metadata": {},
   "outputs": [],
   "source": [
    "clean_imp_cols.columns.tolist();"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 194,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "<ipython-input-194-6907ee131ba6>:1: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  clean_imp_cols['AP_Test Takers'] = clean_imp_cols['AP_Test Takers'].str.replace(',', '')\n"
     ]
    }
   ],
   "source": [
    "clean_imp_cols['AP_Test Takers'] = clean_imp_cols['AP_Test Takers'].str.replace(',', '')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 195,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1037\n",
      "623.0\n",
      "2001.0\n"
     ]
    }
   ],
   "source": [
    "print(pd.to_numeric(clean_imp_cols['AP_Test Takers']).max())\n",
    "print(clean_imp_cols['SAT_Tests Taken'].max())\n",
    "print(clean_imp_cols['Total # of Classes'].max())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Fucntions to Convert Columns to Binary Variables"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 196,
   "metadata": {},
   "outputs": [],
   "source": [
    "def convert_SAT_to_bin(column, first_100, second_100, third_100, fourth_100, fifth_100, sixth_100,seventh_100):\n",
    "    for i in range(len(column)):\n",
    "        if column[i] <= 100:\n",
    "            first_100.append(1)\n",
    "            second_100.append(0)\n",
    "            third_100.append(0)\n",
    "            fourth_100.append(0)\n",
    "            fifth_100.append(0)\n",
    "            sixth_100.append(0)\n",
    "            seventh_100.append(0)\n",
    "        elif ((column[i] > 100) and(column[i] <= 200)):\n",
    "            first_100.append(0)\n",
    "            second_100.append(1)\n",
    "            third_100.append(0)\n",
    "            fourth_100.append(0)\n",
    "            fifth_100.append(0)\n",
    "            sixth_100.append(0)\n",
    "            seventh_100.append(0)\n",
    "        elif ((column[i] > 200) and(column[i] <= 300)):\n",
    "            first_100.append(0)\n",
    "            second_100.append(0)\n",
    "            third_100.append(1)\n",
    "            fourth_100.append(0)\n",
    "            fifth_100.append(0)\n",
    "            sixth_100.append(0)\n",
    "            seventh_100.append(0)\n",
    "        elif ((column[i] > 300) and(column[i] <= 400)):\n",
    "            first_100.append(0)\n",
    "            second_100.append(0)\n",
    "            third_100.append(0)\n",
    "            fourth_100.append(1)\n",
    "            fifth_100.append(0)\n",
    "            sixth_100.append(0)\n",
    "            seventh_100.append(0)\n",
    "        elif ((column[i] > 400) and(column[i] <= 500)):\n",
    "            first_100.append(0)\n",
    "            second_100.append(0)\n",
    "            third_100.append(0)\n",
    "            fourth_100.append(0)\n",
    "            fifth_100.append(1)\n",
    "            sixth_100.append(0)\n",
    "            seventh_100.append(0)\n",
    "        elif ((column[i] > 500) and(column[i] <= 600)):\n",
    "            first_100.append(0)\n",
    "            second_100.append(0)\n",
    "            third_100.append(0)\n",
    "            fourth_100.append(0)\n",
    "            fifth_100.append(0)\n",
    "            sixth_100.append(1)\n",
    "            seventh_100.append(0)\n",
    "        else:\n",
    "            first_100.append(0)\n",
    "            second_100.append(0)\n",
    "            third_100.append(0)\n",
    "            fourth_100.append(0)\n",
    "            fifth_100.append(0)\n",
    "            sixth_100.append(0)\n",
    "            seventh_100.append(1)\n",
    "            \n",
    "    return first_100, second_100, third_100, fourth_100, fifth_100, sixth_100,seventh_100"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 197,
   "metadata": {},
   "outputs": [],
   "source": [
    "def convert_AP_taken_bin(column,first_100, second_100, third_100,fourth_100,\\\n",
    "                         fifth_100, sixth_100, seventh_100,eighth_100,\\\n",
    "                         nineth_100,tenth_100,eleventh_100):\n",
    "    for i in range(len(column)):\n",
    "        if column[i] <= 100:\n",
    "            first_100.append(1)\n",
    "            second_100.append(0)\n",
    "            third_100.append(0)\n",
    "            fourth_100.append(0)\n",
    "            fifth_100.append(0)\n",
    "            sixth_100.append(0)\n",
    "            seventh_100.append(0)\n",
    "            eighth_100.append(0)\n",
    "            nineth_100.append(0)\n",
    "            tenth_100.append(0)\n",
    "            eleventh_100.append(0)\n",
    "        elif ((column[i] > 100) and(column[i] <= 200)):\n",
    "            first_100.append(0)\n",
    "            second_100.append(1)\n",
    "            third_100.append(0)\n",
    "            fourth_100.append(0)\n",
    "            fifth_100.append(0)\n",
    "            sixth_100.append(0)\n",
    "            seventh_100.append(0)\n",
    "            eighth_100.append(0)\n",
    "            nineth_100.append(0)\n",
    "            tenth_100.append(0)\n",
    "            eleventh_100.append(0)\n",
    "        elif ((column[i] > 200) and(column[i] <= 300)):\n",
    "            first_100.append(0)\n",
    "            second_100.append(0)\n",
    "            third_100.append(1)\n",
    "            fourth_100.append(0)\n",
    "            fifth_100.append(0)\n",
    "            sixth_100.append(0)\n",
    "            seventh_100.append(0)\n",
    "            eighth_100.append(0)\n",
    "            nineth_100.append(0)\n",
    "            tenth_100.append(0)\n",
    "            eleventh_100.append(0)\n",
    "        elif ((column[i] > 300) and(column[i] <= 400)):\n",
    "            first_100.append(0)\n",
    "            second_100.append(0)\n",
    "            third_100.append(0)\n",
    "            fourth_100.append(1)\n",
    "            fifth_100.append(0)\n",
    "            sixth_100.append(0)\n",
    "            seventh_100.append(0)\n",
    "            eighth_100.append(0)\n",
    "            nineth_100.append(0)\n",
    "            tenth_100.append(0)\n",
    "            eleventh_100.append(0)\n",
    "        elif ((column[i] > 400) and(column[i] <= 500)):\n",
    "            first_100.append(0)\n",
    "            second_100.append(0)\n",
    "            third_100.append(0)\n",
    "            fourth_100.append(0)\n",
    "            fifth_100.append(1)\n",
    "            sixth_100.append(0)\n",
    "            seventh_100.append(0)\n",
    "            eighth_100.append(0)\n",
    "            nineth_100.append(0)\n",
    "            tenth_100.append(0)\n",
    "            eleventh_100.append(0)\n",
    "        elif ((column[i] > 500) and(column[i] <= 600)):\n",
    "            first_100.append(0)\n",
    "            second_100.append(0)\n",
    "            third_100.append(0)\n",
    "            fourth_100.append(0)\n",
    "            fifth_100.append(0)\n",
    "            sixth_100.append(1)\n",
    "            seventh_100.append(0)\n",
    "            eighth_100.append(0)\n",
    "            nineth_100.append(0)\n",
    "            tenth_100.append(0)\n",
    "            eleventh_100.append(0)\n",
    "        elif ((column[i] > 600) and(column[i] <=700)):\n",
    "            first_100.append(0)\n",
    "            second_100.append(0)\n",
    "            third_100.append(0)\n",
    "            fourth_100.append(0)\n",
    "            fifth_100.append(0)\n",
    "            sixth_100.append(0)\n",
    "            seventh_100.append(1)\n",
    "            eighth_100.append(0)\n",
    "            nineth_100.append(0)\n",
    "            tenth_100.append(0)\n",
    "            eleventh_100.append(0)\n",
    "        elif ((column[i] > 700) and(column[i] <=800)):\n",
    "            first_100.append(0)\n",
    "            second_100.append(0)\n",
    "            third_100.append(0)\n",
    "            fourth_100.append(0)\n",
    "            fifth_100.append(0)\n",
    "            sixth_100.append(0)\n",
    "            seventh_100.append(0)\n",
    "            eighth_100.append(1)\n",
    "            nineth_100.append(0)\n",
    "            tenth_100.append(0)\n",
    "            eleventh_100.append(0)\n",
    "        elif ((column[i] > 800) and(column[i] <=900)):\n",
    "            first_100.append(0)\n",
    "            second_100.append(0)\n",
    "            third_100.append(0)\n",
    "            fourth_100.append(0)\n",
    "            fifth_100.append(0)\n",
    "            sixth_100.append(0)\n",
    "            seventh_100.append(0)\n",
    "            eighth_100.append(0)\n",
    "            nineth_100.append(1)\n",
    "            tenth_100.append(0)\n",
    "            eleventh_100.append(0)\n",
    "        elif ((column[i] > 900) and(column[i] <=1000)):\n",
    "            first_100.append(0)\n",
    "            second_100.append(0)\n",
    "            third_100.append(0)\n",
    "            fourth_100.append(0)\n",
    "            fifth_100.append(0)\n",
    "            sixth_100.append(0)\n",
    "            seventh_100.append(0)\n",
    "            eighth_100.append(0)\n",
    "            nineth_100.append(0)\n",
    "            tenth_100.append(1)\n",
    "            eleventh_100.append(0)\n",
    "        else:\n",
    "            first_100.append(0)\n",
    "            second_100.append(0)\n",
    "            third_100.append(0)\n",
    "            fourth_100.append(0)\n",
    "            fifth_100.append(0)\n",
    "            sixth_100.append(0)\n",
    "            seventh_100.append(0)\n",
    "            eighth_100.append(0)\n",
    "            nineth_100.append(0)\n",
    "            tenth_100.append(0)\n",
    "            eleventh_100.append(1)\n",
    "    \n",
    "    return first_100,second_100,third_100,fourth_100,fifth_100,sixth_100,seventh_100,eighth_100,\\\n",
    "           nineth_100,tenth_100, eleventh_100"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 198,
   "metadata": {},
   "outputs": [],
   "source": [
    "def convert_tot_class_bin(column, fist_250, second_250, third_250, fourth_250, fifth_250,\\\n",
    "                          sitxth_250, seventh_250,eight_250, nineth_250):\n",
    "    for i in range(len(column)):\n",
    "        if column[i] <= 250:\n",
    "            fist_250.append(1) \n",
    "            second_250.append(0) \n",
    "            third_250.append(0) \n",
    "            fourth_250.append(0)\n",
    "            fifth_250.append(0)\n",
    "            sitxth_250.append(0)\n",
    "            seventh_250.append(0)\n",
    "            eight_250.append(0)\n",
    "            nineth_250.append(0)\n",
    "        elif ((column[i] > 250) and (column[i] <=500)):\n",
    "            fist_250.append(0) \n",
    "            second_250.append(1) \n",
    "            third_250.append(0) \n",
    "            fourth_250.append(0)\n",
    "            fifth_250.append(0)\n",
    "            sitxth_250.append(0)\n",
    "            seventh_250.append(0)\n",
    "            eight_250.append(0)\n",
    "            nineth_250.append(0)\n",
    "        elif ((column[i] > 500) and (column[i] <=750)):\n",
    "            fist_250.append(0) \n",
    "            second_250.append(0) \n",
    "            third_250.append(1) \n",
    "            fourth_250.append(0)\n",
    "            fifth_250.append(0)\n",
    "            sitxth_250.append(0)\n",
    "            seventh_250.append(0)\n",
    "            eight_250.append(0)\n",
    "            nineth_250.append(0)\n",
    "        elif ((column[i] > 750) and (column[i] <1000)):\n",
    "            fist_250.append(0) \n",
    "            second_250.append(0) \n",
    "            third_250.append(0) \n",
    "            fourth_250.append(1)\n",
    "            fifth_250.append(0)\n",
    "            sitxth_250.append(0)\n",
    "            seventh_250.append(0)\n",
    "            eight_250.append(0)\n",
    "            nineth_250.append(0)\n",
    "        elif ((column[i] > 1000) and (column[i] <=1250)):\n",
    "            fist_250.append(0) \n",
    "            second_250.append(0) \n",
    "            third_250.append(0) \n",
    "            fourth_250.append(0)\n",
    "            fifth_250.append(1)\n",
    "            sitxth_250.append(0)\n",
    "            seventh_250.append(0)\n",
    "            eight_250.append(0)\n",
    "            nineth_250.append(0)\n",
    "        elif ((column[i] > 1250) and (column[i] <=1500)):\n",
    "            fist_250.append(0) \n",
    "            second_250.append(0) \n",
    "            third_250.append(0) \n",
    "            fourth_250.append(0)\n",
    "            fifth_250.append(0)\n",
    "            sitxth_250.append(1)\n",
    "            seventh_250.append(0)\n",
    "            eight_250.append(0)\n",
    "            nineth_250.append(0)\n",
    "        elif ((column[i] > 1500) and (column[i] <=1750)):\n",
    "            fist_250.append(0) \n",
    "            second_250.append(0) \n",
    "            third_250.append(0) \n",
    "            fourth_250.append(0)\n",
    "            fifth_250.append(0)\n",
    "            sitxth_250.append(0)\n",
    "            seventh_250.append(1)\n",
    "            eight_250.append(0)\n",
    "            nineth_250.append(0)\n",
    "        elif ((column[i] > 1750) and (column[i] <=2000)):\n",
    "            fist_250.append(0) \n",
    "            second_250.append(0) \n",
    "            third_250.append(0) \n",
    "            fourth_250.append(0)\n",
    "            fifth_250.append(0)\n",
    "            sitxth_250.append(0)\n",
    "            seventh_250.append(0)\n",
    "            eight_250.append(1)\n",
    "            nineth_250.append(0)\n",
    "        else:\n",
    "            fist_250.append(0) \n",
    "            second_250.append(0) \n",
    "            third_250.append(0) \n",
    "            fourth_250.append(0)\n",
    "            fifth_250.append(0)\n",
    "            sitxth_250.append(0)\n",
    "            seventh_250.append(0)\n",
    "            eight_250.append(0)\n",
    "            nineth_250.append(1)\n",
    "            \n",
    "    return fist_250, second_250, third_250, fourth_250, fifth_250,sitxth_250, seventh_250,eight_250, nineth_250\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 199,
   "metadata": {},
   "outputs": [],
   "source": [
    "def convert_to_thirds_perc(column,first_third,middle_third,last_third):\n",
    "    for i in range(len(column)):\n",
    "        if column[i] <= 33.0:\n",
    "            first_third.append(1)\n",
    "            middle_third.append(0)\n",
    "            last_third.append(0)\n",
    "        elif (column[i] > 33.0 and column[i] <=66.0):\n",
    "            first_third.append(0)\n",
    "            middle_third.append(1)\n",
    "            last_third.append(0)\n",
    "        else:\n",
    "            first_third.append(0)\n",
    "            middle_third.append(0)\n",
    "            last_third.append(1)\n",
    "            \n",
    "    return first_third,middle_third,last_third"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 200,
   "metadata": {},
   "outputs": [],
   "source": [
    "def convert_outcome_bin(column,bin_outcome):\n",
    "    for i in range(len(column)):\n",
    "        if column[i] < 64.6:\n",
    "            bin_outcome.append(-1)\n",
    "        else:\n",
    "            bin_outcome.append(1)\n",
    "    \n",
    "    return bin_outcome"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 201,
   "metadata": {},
   "outputs": [],
   "source": [
    "def convert_tot_enroll_binary(column, first_500, second_500, third_500, \\\n",
    "                              fourth_500, fifth_500, sixth_500, seventh_500, \\\n",
    "                              eighth_500, nineth_500):\n",
    "    for i in range(len(column)):\n",
    "        if column[i] <= 500:\n",
    "            first_500.append(1)\n",
    "            second_500.append(0)\n",
    "            third_500.append(0)\n",
    "            fourth_500.append(0)\n",
    "            fifth_500.append(0)\n",
    "            sixth_500.append(0)\n",
    "            seventh_500.append(0)\n",
    "            eighth_500.append(0)\n",
    "            nineth_500.append(0)\n",
    "        elif ((column[i] > 500) and(column[i] <= 1000)):\n",
    "            first_500.append(0)\n",
    "            second_500.append(1)\n",
    "            third_500.append(0)\n",
    "            fourth_500.append(0)\n",
    "            fifth_500.append(0)\n",
    "            sixth_500.append(0)\n",
    "            seventh_500.append(0)\n",
    "            eighth_500.append(0)\n",
    "            nineth_500.append(0)\n",
    "        elif ((column[i] > 1000) and(column[i] <= 1500)):\n",
    "            first_500.append(0)\n",
    "            second_500.append(0)\n",
    "            third_500.append(1)\n",
    "            fourth_500.append(0)\n",
    "            fifth_500.append(0)\n",
    "            sixth_500.append(0)\n",
    "            seventh_500.append(0)\n",
    "            eighth_500.append(0)\n",
    "            nineth_500.append(0)\n",
    "        elif ((column[i] > 1500) and(column[i] <= 2000)):\n",
    "            first_500.append(0)\n",
    "            second_500.append(0)\n",
    "            third_500.append(0)\n",
    "            fourth_500.append(1)\n",
    "            fifth_500.append(0)\n",
    "            sixth_500.append(0)\n",
    "            seventh_500.append(0)\n",
    "            eighth_500.append(0)\n",
    "            nineth_500.append(0)\n",
    "        elif ((column[i] > 2000) and(column[i] <= 2500)):\n",
    "            first_500.append(0)\n",
    "            second_500.append(0)\n",
    "            third_500.append(0)\n",
    "            fourth_500.append(0)\n",
    "            fifth_500.append(1)\n",
    "            sixth_500.append(0)\n",
    "            seventh_500.append(0)\n",
    "            eighth_500.append(0)\n",
    "            nineth_500.append(0)\n",
    "        elif ((column[i] > 2500) and(column[i] <= 3000)):\n",
    "            first_500.append(0)\n",
    "            second_500.append(0)\n",
    "            third_500.append(0)\n",
    "            fourth_500.append(0)\n",
    "            fifth_500.append(0)\n",
    "            sixth_500.append(1)\n",
    "            seventh_500.append(0)\n",
    "            eighth_500.append(0)\n",
    "            nineth_500.append(0)\n",
    "        elif ((column[i] > 3000) and(column[i] <=3500)):\n",
    "            first_500.append(0)\n",
    "            second_500.append(0)\n",
    "            third_500.append(0)\n",
    "            fourth_500.append(0)\n",
    "            fifth_500.append(0)\n",
    "            sixth_500.append(0)\n",
    "            seventh_500.append(1)\n",
    "            eighth_500.append(0)\n",
    "            nineth_500.append(0)\n",
    "        elif ((column[i] > 3500) and(column[i] <=4000)):\n",
    "            first_500.append(0)\n",
    "            second_500.append(0)\n",
    "            third_500.append(0)\n",
    "            fourth_500.append(0)\n",
    "            fifth_500.append(0)\n",
    "            sixth_500.append(0)\n",
    "            seventh_500.append(0)\n",
    "            eighth_500.append(1)\n",
    "            nineth_500.append(0)\n",
    "        else:\n",
    "            first_500.append(0)\n",
    "            second_500.append(0)\n",
    "            third_500.append(0)\n",
    "            fourth_500.append(0)\n",
    "            fifth_500.append(0)\n",
    "            sixth_500.append(0)\n",
    "            seventh_500.append(0)\n",
    "            eighth_500.append(0)\n",
    "            nineth_500.append(1)\n",
    "    \n",
    "    return first_500,second_500,third_500,fourth_500,fifth_500,sixth_500,seventh_500,eighth_500,nineth_500"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 202,
   "metadata": {},
   "outputs": [],
   "source": [
    "def convert_12th_enroll_binary(column, first_100, second_100, third_100, \\\n",
    "                              fourth_100, fifth_100, sixth_100, seventh_100, \\\n",
    "                              eighth_100, nineth_100,tenth_100):\n",
    "    for i in range(len(column)):\n",
    "        if column[i] <= 100:\n",
    "            first_100.append(1)\n",
    "            second_100.append(0)\n",
    "            third_100.append(0)\n",
    "            fourth_100.append(0)\n",
    "            fifth_100.append(0)\n",
    "            sixth_100.append(0)\n",
    "            seventh_100.append(0)\n",
    "            eighth_100.append(0)\n",
    "            nineth_100.append(0)\n",
    "            tenth_100.append(0)\n",
    "        elif ((column[i] > 100) and(column[i] <= 200)):\n",
    "            first_100.append(0)\n",
    "            second_100.append(1)\n",
    "            third_100.append(0)\n",
    "            fourth_100.append(0)\n",
    "            fifth_100.append(0)\n",
    "            sixth_100.append(0)\n",
    "            seventh_100.append(0)\n",
    "            eighth_100.append(0)\n",
    "            nineth_100.append(0)\n",
    "            tenth_100.append(0)\n",
    "        elif ((column[i] > 200) and(column[i] <= 300)):\n",
    "            first_100.append(0)\n",
    "            second_100.append(0)\n",
    "            third_100.append(1)\n",
    "            fourth_100.append(0)\n",
    "            fifth_100.append(0)\n",
    "            sixth_100.append(0)\n",
    "            seventh_100.append(0)\n",
    "            eighth_100.append(0)\n",
    "            nineth_100.append(0)\n",
    "            tenth_100.append(0)\n",
    "        elif ((column[i] > 300) and(column[i] <= 400)):\n",
    "            first_100.append(0)\n",
    "            second_100.append(0)\n",
    "            third_100.append(0)\n",
    "            fourth_100.append(1)\n",
    "            fifth_100.append(0)\n",
    "            sixth_100.append(0)\n",
    "            seventh_100.append(0)\n",
    "            eighth_100.append(0)\n",
    "            nineth_100.append(0)\n",
    "            tenth_100.append(0)\n",
    "        elif ((column[i] > 400) and(column[i] <= 500)):\n",
    "            first_100.append(0)\n",
    "            second_100.append(0)\n",
    "            third_100.append(0)\n",
    "            fourth_100.append(0)\n",
    "            fifth_100.append(1)\n",
    "            sixth_100.append(0)\n",
    "            seventh_100.append(0)\n",
    "            eighth_100.append(0)\n",
    "            nineth_100.append(0)\n",
    "            tenth_100.append(0)\n",
    "        elif ((column[i] > 500) and(column[i] <= 600)):\n",
    "            first_100.append(0)\n",
    "            second_100.append(0)\n",
    "            third_100.append(0)\n",
    "            fourth_100.append(0)\n",
    "            fifth_100.append(0)\n",
    "            sixth_100.append(1)\n",
    "            seventh_100.append(0)\n",
    "            eighth_100.append(0)\n",
    "            nineth_100.append(0)\n",
    "            tenth_100.append(0)\n",
    "        elif ((column[i] > 600) and(column[i] <=700)):\n",
    "            first_100.append(0)\n",
    "            second_100.append(0)\n",
    "            third_100.append(0)\n",
    "            fourth_100.append(0)\n",
    "            fifth_100.append(0)\n",
    "            sixth_100.append(0)\n",
    "            seventh_100.append(1)\n",
    "            eighth_100.append(0)\n",
    "            nineth_100.append(0)\n",
    "            tenth_100.append(0)\n",
    "        elif ((column[i] > 700) and(column[i] <=800)):\n",
    "            first_100.append(0)\n",
    "            second_100.append(0)\n",
    "            third_100.append(0)\n",
    "            fourth_100.append(0)\n",
    "            fifth_100.append(0)\n",
    "            sixth_100.append(0)\n",
    "            seventh_100.append(0)\n",
    "            eighth_100.append(1)\n",
    "            nineth_100.append(0)\n",
    "            tenth_100.append(0)\n",
    "        elif ((column[i] > 800) and(column[i] <=900)):\n",
    "            first_100.append(0)\n",
    "            second_100.append(0)\n",
    "            third_100.append(0)\n",
    "            fourth_100.append(0)\n",
    "            fifth_100.append(0)\n",
    "            sixth_100.append(0)\n",
    "            seventh_100.append(0)\n",
    "            eighth_100.append(0)\n",
    "            nineth_100.append(1)\n",
    "            tenth_100.append(0)\n",
    "        else:\n",
    "            first_100.append(0)\n",
    "            second_100.append(0)\n",
    "            third_100.append(0)\n",
    "            fourth_100.append(0)\n",
    "            fifth_100.append(0)\n",
    "            sixth_100.append(0)\n",
    "            seventh_100.append(0)\n",
    "            eighth_100.append(0)\n",
    "            nineth_100.append(0)\n",
    "            tenth_100.append(1)\n",
    "    \n",
    "    return first_100,second_100,third_100,fourth_100,fifth_100,sixth_100,seventh_100,eighth_100, nineth_100,tenth_100"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 203,
   "metadata": {},
   "outputs": [],
   "source": [
    "def convert_class_size_bin(column, first_5, second_5, third_5, fourth_5, fifth_5, sixth_5, seventh_5):\n",
    "    for i in range(len(column)):\n",
    "        if column[i] <= 5:\n",
    "            first_5.append(1)\n",
    "            second_5.append(0)\n",
    "            third_5.append(0)\n",
    "            fourth_5.append(0)\n",
    "            fifth_5.append(0)\n",
    "            sixth_5.append(0)\n",
    "            seventh_5.append(0)\n",
    "        elif ((column[i] > 5) and (column[i] <= 10)):\n",
    "            first_5.append(0)\n",
    "            second_5.append(1)\n",
    "            third_5.append(0)\n",
    "            fourth_5.append(0)\n",
    "            fifth_5.append(0)\n",
    "            sixth_5.append(0)\n",
    "            seventh_5.append(0)\n",
    "        elif ((column[i] > 10) and (column[i] <= 15)):\n",
    "            first_5.append(0)\n",
    "            second_5.append(0)\n",
    "            third_5.append(1)\n",
    "            fourth_5.append(0)\n",
    "            fifth_5.append(0)\n",
    "            sixth_5.append(0)\n",
    "            seventh_5.append(0)\n",
    "        elif ((column[i] > 15) and (column[i] <= 20)):\n",
    "            first_5.append(0)\n",
    "            second_5.append(0)\n",
    "            third_5.append(0)\n",
    "            fourth_5.append(1)\n",
    "            fifth_5.append(0)\n",
    "            sixth_5.append(0)\n",
    "            seventh_5.append(0)\n",
    "        elif ((column[i] > 20) and (column[i] <= 25)):\n",
    "            first_5.append(0)\n",
    "            second_5.append(0)\n",
    "            third_5.append(0)\n",
    "            fourth_5.append(0)\n",
    "            fifth_5.append(1)\n",
    "            sixth_5.append(0)\n",
    "            seventh_5.append(0)\n",
    "        elif ((column[i] > 25) and (column[i] <= 30)):\n",
    "            first_5.append(0)\n",
    "            second_5.append(0)\n",
    "            third_5.append(0)\n",
    "            fourth_5.append(0)\n",
    "            fifth_5.append(0)\n",
    "            sixth_5.append(1)\n",
    "            seventh_5.append(0)\n",
    "        else:\n",
    "            first_5.append(0)\n",
    "            second_5.append(0)\n",
    "            third_5.append(0)\n",
    "            fourth_5.append(0)\n",
    "            fifth_5.append(0)\n",
    "            sixth_5.append(0)\n",
    "            seventh_5.append(1)\n",
    "            \n",
    "    return first_5, second_5, third_5, fourth_5, fifth_5, sixth_5, seventh_5"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Actually converting columns to binary variables"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 204,
   "metadata": {},
   "outputs": [],
   "source": [
    "#convert columns to arrays for functions\n",
    "# disab_array = np.array(clean_imp_cols['Percent Students With Disabilities'])\n",
    "# high_needs_array = np.array(clean_imp_cols['Percent High Needs'])\n",
    "# econ_dis_array = np.array(clean_imp_cols['Percent Economically Disadvantaged'])\n",
    "# african_array = np.array(clean_imp_cols['Percent African American'])\n",
    "# asian_array = np.array(clean_imp_cols['Percent Asian'])\n",
    "# hispanic_array = np.array(clean_imp_cols['Percent Hispanic'])\n",
    "# white_array = np.array(clean_imp_cols['Percent White'])\n",
    "# native_array = np.array(clean_imp_cols['Percent Native American'])\n",
    "# pacific_array = np.array(clean_imp_cols['Percent Native Hawaiian, Pacific Islander'])\n",
    "# multi_race_array = np.array(clean_imp_cols['Percent Multi-Race, Non-Hispanic'])\n",
    "\n",
    "ap_test_taken_1_array = np.array(clean_imp_cols['AP_One Test'])\n",
    "ap_test_taken_2_array = np.array(clean_imp_cols['AP_Two Tests'])\n",
    "ap_test_taken_3_array = np.array(clean_imp_cols['AP_Three Tests'])\n",
    "ap_test_taken_4_array = np.array(clean_imp_cols['AP_Four Tests'])\n",
    "ap_test_taken_5_plus_array = np.array(clean_imp_cols['AP_Five or More Tests'])\n",
    "\n",
    "\n",
    "not_eng_array = np.array(clean_imp_cols['Percent First Language Not English'])\n",
    "\n",
    "\n",
    "\n",
    "#Create empty lists for conversion function\n",
    "# disab_33_below = []\n",
    "# disab_33_66 = []\n",
    "# disab_66_above = []\n",
    "\n",
    "# high_needs_33_below = []\n",
    "# high_needs_33_66 = []\n",
    "# high_needs_66_above = []\n",
    "\n",
    "# econ_dis_33_below = []\n",
    "# econ_dis_33_66 = []\n",
    "# econ_dis_66_above = []\n",
    "\n",
    "# african_33_below = []\n",
    "# african_33_66 = []\n",
    "# african_66_above = []\n",
    "\n",
    "# asian_33_below = []\n",
    "# asian_33_66 = []\n",
    "# asian_66_above = []\n",
    "\n",
    "# hispanic_33_below = []\n",
    "# hispanic_33_66 = []\n",
    "# hispanic_66_above = []\n",
    "\n",
    "# white_33_below = []\n",
    "# white_33_66 = []\n",
    "# white_66_above = []\n",
    "\n",
    "# native_33_below = []\n",
    "# native_33_66 = []\n",
    "# native_66_above = []\n",
    "\n",
    "# pacific_33_below = []\n",
    "# pacific_33_66 = []\n",
    "# pacific_66_above = []\n",
    "\n",
    "# multi_race_33_below = []\n",
    "# multi_race_33_66 = []\n",
    "# multi_race_66_above = []\n",
    "\n",
    "ap_test_taken_1_33_below = []\n",
    "ap_test_taken_1_33_66 = []\n",
    "ap_test_taken_1_66_above = []\n",
    "\n",
    "ap_test_taken_2_33_below = []\n",
    "ap_test_taken_2_33_66 = []\n",
    "ap_test_taken_2_66_above = []\n",
    "\n",
    "ap_test_taken_3_33_below = []\n",
    "ap_test_taken_3_33_66 = []\n",
    "ap_test_taken_3_66_above = []\n",
    "\n",
    "ap_test_taken_4_33_below = []\n",
    "ap_test_taken_4_33_66 = []\n",
    "ap_test_taken_4_66_above = []\n",
    "\n",
    "ap_test_taken_5_plus_33_below = []\n",
    "ap_test_taken_5_plus_33_66 = []\n",
    "ap_test_taken_5_plus_66_above = []\n",
    "\n",
    "not_eng_33_below = []\n",
    "not_eng_33_66 = []\n",
    "not_eng_66_above = []\n",
    "\n",
    "#Calling conversion fucntion\n",
    "# disab_33_below,disab_33_66,disab_66_above = convert_to_thirds_perc(disab_array,disab_33_below,disab_33_66,disab_66_above);\n",
    "# high_needs_33_below,high_needs_33_66,high_needs_66_above = convert_to_thirds_perc(high_needs_array,high_needs_33_below,high_needs_33_66,high_needs_66_above);\n",
    "# econ_dis_33_below,econ_dis_33_66,econ_dis_66_above = convert_to_thirds_perc(econ_dis_array,econ_dis_33_below,econ_dis_33_66,econ_dis_66_above);\n",
    "# african_33_below,african_33_66,african_66_above = convert_to_thirds_perc(african_array,african_33_below,african_33_66,african_66_above);\n",
    "# asian_33_below,asian_33_66,asian_66_above = convert_to_thirds_perc(asian_array,asian_33_below,asian_33_66,asian_66_above);\n",
    "# hispanic_33_below,hispanic_33_66,hispanic_66_above = convert_to_thirds_perc(hispanic_array,hispanic_33_below,hispanic_33_66,hispanic_66_above);\n",
    "# white_33_below,white_33_66,white_66_above = convert_to_thirds_perc(white_array,white_33_below,white_33_66,white_66_above);\n",
    "# native_33_below,native_33_66,native_66_above = convert_to_thirds_perc(native_array,native_33_below,native_33_66,native_66_above);\n",
    "# pacific_33_below,pacific_33_66,pacific_66_above = convert_to_thirds_perc(pacific_array,pacific_33_below,pacific_33_66,pacific_66_above);\n",
    "# multi_race_33_below,multi_race_33_66,multi_race_66_above = convert_to_thirds_perc(multi_race_array,multi_race_33_below,multi_race_33_66,multi_race_66_above);\n",
    "\n",
    "\n",
    "ap_test_taken_1_33_below,ap_test_taken_1_33_66,ap_test_taken_1_66_above = convert_to_thirds_perc(ap_test_taken_1_array,ap_test_taken_1_33_below,ap_test_taken_1_33_66,ap_test_taken_1_66_above);\n",
    "ap_test_taken_2_33_below,ap_test_taken_2_33_66,ap_test_taken_2_66_above = convert_to_thirds_perc(ap_test_taken_2_array,ap_test_taken_2_33_below,ap_test_taken_2_33_66,ap_test_taken_2_66_above);\n",
    "ap_test_taken_3_33_below,ap_test_taken_3_33_66,ap_test_taken_3_66_above = convert_to_thirds_perc(ap_test_taken_3_array,ap_test_taken_3_33_below,ap_test_taken_3_33_66,ap_test_taken_3_66_above);\n",
    "ap_test_taken_4_33_below,ap_test_taken_4_33_66,ap_test_taken_4_66_above = convert_to_thirds_perc(ap_test_taken_4_array,ap_test_taken_4_33_below,ap_test_taken_4_33_66,ap_test_taken_4_66_above);\n",
    "ap_test_taken_5_plus_33_below,ap_test_taken_5_plus_33_66,ap_test_taken_5_plus_66_above = convert_to_thirds_perc(ap_test_taken_5_plus_array,ap_test_taken_5_plus_33_below,ap_test_taken_5_plus_33_66,ap_test_taken_5_plus_66_above);\n",
    "\n",
    "not_eng_33_below,not_eng_33_66,not_eng_66_above = convert_to_thirds_perc(not_eng_array,not_eng_33_below,not_eng_33_66,not_eng_66_above);"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 205,
   "metadata": {},
   "outputs": [],
   "source": [
    "#convert college percentage to binary outcomes\n",
    "outcome_array = np.array(clean_imp_cols['Percent Attending College'])\n",
    "outcome_bin = []\n",
    "\n",
    "outcome_bin = convert_outcome_bin(outcome_array,outcome_bin)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 206,
   "metadata": {},
   "outputs": [],
   "source": [
    "# enroll_12th_array = np.array(clean_imp_cols['12_Enrollment'])\n",
    "tot_enroll_array = np.array(clean_imp_cols['TOTAL_Enrollment'])\n",
    "avg_class_array = np.array(clean_imp_cols['Average Class Size'])\n",
    "SAT_taken_array = np.array(clean_imp_cols['SAT_Tests Taken'])\n",
    "AP_taken_array = np.array(pd.to_numeric(clean_imp_cols['AP_Test Takers']))\n",
    "Tot_num_classes_array = np.array(clean_imp_cols['Total # of Classes'])\n",
    "\n",
    "enroll_12th_0_100 = []\n",
    "enroll_12th_100_200 = []\n",
    "enroll_12th_200_300 = []\n",
    "enroll_12th_300_400 = []\n",
    "enroll_12th_400_500 = []\n",
    "enroll_12th_500_600 = []\n",
    "enroll_12th_600_700 = []\n",
    "enroll_12th_700_800 = []\n",
    "enroll_12th_800_900 = []\n",
    "enroll_12th_900_1000 = []\n",
    "\n",
    "tot_enroll_0_500 = []\n",
    "tot_enroll_500_1000 = []\n",
    "tot_enroll_1000_1500 = []\n",
    "tot_enroll_1500_2000 = []\n",
    "tot_enroll_2000_2500 = []\n",
    "tot_enroll_2500_3000 = []\n",
    "tot_enroll_3000_3500 = []\n",
    "tot_enroll_3500_4000 = []\n",
    "tot_enroll_4000_4500 = []\n",
    "\n",
    "avg_class_0_5 = []\n",
    "avg_class_5_10 = []\n",
    "avg_class_10_15 = []\n",
    "avg_class_15_20 = []\n",
    "avg_class_20_25 = []\n",
    "avg_class_25_30 = []\n",
    "avg_class_30_35 = []\n",
    "\n",
    "SAT_taken_0_100 = [];\n",
    "SAT_taken_100_200 = [];\n",
    "SAT_taken_200_300 = [];\n",
    "SAT_taken_300_400 = [];\n",
    "SAT_taken_400_500 = [];\n",
    "SAT_taken_500_600 = [];\n",
    "SAT_taken_600_700 = [];\n",
    "\n",
    "AP_taken_0_100 = [];\n",
    "AP_taken_100_200 = [];\n",
    "AP_taken_200_300 = [];\n",
    "AP_taken_300_400 = [];\n",
    "AP_taken_400_500 = [];\n",
    "AP_taken_500_600 = [];\n",
    "AP_taken_600_700 = [];\n",
    "AP_taken_700_800 = [];\n",
    "AP_taken_800_900 = [];\n",
    "AP_taken_900_1000 = [];\n",
    "AP_taken_1000_1100 = [];\n",
    "\n",
    "Tot_num_classes_0_250 = [];\n",
    "Tot_num_classes_250_500 = [];\n",
    "Tot_num_classes_500_750 = [];\n",
    "Tot_num_classes_750_1000 = [];\n",
    "Tot_num_classes_1000_1250 = [];\n",
    "Tot_num_classes_1250_1500 = [];\n",
    "Tot_num_classes_1500_1750 = [];\n",
    "Tot_num_classes_1750_2000 = [];\n",
    "Tot_num_classes_2000_2250 = [];\n",
    "\n",
    "\n",
    "# enroll_12th_0_100,enroll_12th_100_200,enroll_12th_200_300,\\\n",
    "# enroll_12th_300_400,enroll_12th_400_500,enroll_12th_500_600,\\\n",
    "# enroll_12th_600_700,enroll_12th_700_800,enroll_12th_800_900,\\\n",
    "# enroll_12th_900_1000 = convert_12th_enroll_binary(enroll_12th_array,enroll_12th_0_100,enroll_12th_100_200,\\\n",
    "#                                                   enroll_12th_200_300, enroll_12th_300_400,enroll_12th_400_500,\\\n",
    "#                                                   enroll_12th_500_600,enroll_12th_600_700,enroll_12th_700_800,\\\n",
    "#                                                   enroll_12th_800_900,enroll_12th_900_1000);\n",
    "\n",
    "tot_enroll_0_500,tot_enroll_500_1000,tot_enroll_1000_1500,\\\n",
    "tot_enroll_1500_2000,tot_enroll_2000_2500,tot_enroll_2500_3000,\\\n",
    "tot_enroll_3000_3500,tot_enroll_3500_4000,tot_enroll_4000_4500 = convert_tot_enroll_binary(tot_enroll_array,\\\n",
    "                                                                                           tot_enroll_0_500,\\\n",
    "                                                                                           tot_enroll_500_1000,\\\n",
    "                                                                                           tot_enroll_1000_1500,\\\n",
    "                                                                                           tot_enroll_1500_2000,\\\n",
    "                                                                                           tot_enroll_2000_2500,\\\n",
    "                                                                                           tot_enroll_2500_3000,\\\n",
    "                                                                                           tot_enroll_3000_3500,\\\n",
    "                                                                                           tot_enroll_3500_4000,\\\n",
    "                                                                                           tot_enroll_4000_4500);\n",
    "\n",
    "avg_class_0_5,avg_class_5_10,avg_class_10_15,\\\n",
    "avg_class_15_20,avg_class_20_25,avg_class_25_30,\\\n",
    "avg_class_30_35 = convert_class_size_bin(avg_class_array,avg_class_0_5,avg_class_5_10,avg_class_10_15,\\\n",
    "                                         avg_class_15_20,avg_class_20_25,avg_class_25_30,avg_class_30_35)\n",
    "\n",
    "SAT_taken_0_100,SAT_taken_100_200,SAT_taken_200_300,SAT_taken_300_400,\\\n",
    "SAT_taken_400_500,SAT_taken_500_600,SAT_taken_600_700=convert_SAT_to_bin(SAT_taken_array,SAT_taken_0_100,\\\n",
    "                                                                         SAT_taken_100_200,SAT_taken_200_300,\\\n",
    "                                                                         SAT_taken_300_400,SAT_taken_400_500,\\\n",
    "                                                                         SAT_taken_500_600,SAT_taken_600_700)\n",
    "AP_taken_0_100,AP_taken_100_200,AP_taken_200_300,AP_taken_300_400,\\\n",
    "AP_taken_400_500,AP_taken_500_600,AP_taken_600_700,AP_taken_700_800,\\\n",
    "AP_taken_800_900, AP_taken_900_1000,AP_taken_1000_1100 =convert_AP_taken_bin(AP_taken_array,AP_taken_0_100,\\\n",
    "                                                                             AP_taken_100_200,AP_taken_200_300,\\\n",
    "                                                                             AP_taken_300_400,AP_taken_400_500,\\\n",
    "                                                                             AP_taken_500_600,AP_taken_600_700,\\\n",
    "                                                                             AP_taken_700_800,AP_taken_800_900,\\\n",
    "                                                                             AP_taken_900_1000,AP_taken_1000_1100)\n",
    "Tot_num_classes_0_250,Tot_num_classes_250_500,Tot_num_classes_500_750,\\\n",
    "Tot_num_classes_750_1000,Tot_num_classes_1000_1250,Tot_num_classes_1250_1500,\\\n",
    "Tot_num_classes_1500_1750,Tot_num_classes_1750_2000,\\\n",
    "Tot_num_classes_2000_2250 =convert_tot_class_bin(Tot_num_classes_array,Tot_num_classes_0_250,Tot_num_classes_250_500,\\\n",
    "                                                 Tot_num_classes_500_750,Tot_num_classes_750_1000,\\\n",
    "                                                 Tot_num_classes_1000_1250,Tot_num_classes_1250_1500,\\\n",
    "                                                 Tot_num_classes_1500_1750,Tot_num_classes_1750_2000,\\\n",
    "                                                 Tot_num_classes_2000_2250)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 207,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "295\n"
     ]
    }
   ],
   "source": [
    "print(len(Tot_num_classes_array))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Add new binary columns to dataframe"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 208,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "<ipython-input-208-e00842228384>:76: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  clean_imp_cols[new_col_names[i]] = pd.DataFrame(columns_to_add[i], index=clean_imp_cols.index)\n"
     ]
    }
   ],
   "source": [
    "# columns_to_add = [disab_33_below,disab_33_66,disab_66_above,high_needs_33_below,high_needs_33_66,\\\n",
    "#                   high_needs_66_above,econ_dis_33_below,econ_dis_33_66,econ_dis_66_above,\\\n",
    "#                   african_33_below,african_33_66,african_66_above,asian_33_below,asian_33_66,\\\n",
    "#                   asian_66_above,hispanic_33_below,hispanic_33_66,hispanic_66_above,white_33_below,\\\n",
    "#                   white_33_66,white_66_above,native_33_below,native_33_66,native_66_above,pacific_33_below,\\\n",
    "#                   pacific_33_66,pacific_66_above,multi_race_33_below,multi_race_33_66,multi_race_66_above,\\\n",
    "#                   ap_test_taken_1_33_below,ap_test_taken_1_33_66,ap_test_taken_1_66_above,ap_test_taken_2_33_below,\\\n",
    "#                   ap_test_taken_2_33_66,ap_test_taken_2_66_above,ap_test_taken_3_33_below,ap_test_taken_3_33_66,\\\n",
    "#                   ap_test_taken_3_66_above,ap_test_taken_4_33_below,ap_test_taken_4_33_66,ap_test_taken_4_66_above,\\\n",
    "#                   ap_test_taken_5_plus_33_below,ap_test_taken_5_plus_33_66,ap_test_taken_5_plus_66_above,\\\n",
    "#                   not_eng_33_below,not_eng_33_66,not_eng_66_above,enroll_12th_0_100,enroll_12th_100_200,\\\n",
    "#                   enroll_12th_200_300,enroll_12th_300_400,enroll_12th_400_500,enroll_12th_500_600,enroll_12th_600_700,\\\n",
    "#                   enroll_12th_700_800,enroll_12th_800_900,enroll_12th_900_1000,tot_enroll_0_500,\\\n",
    "#                   tot_enroll_500_1000,tot_enroll_1000_1500,tot_enroll_1500_2000,tot_enroll_2000_2500,\\\n",
    "#                   tot_enroll_2500_3000,tot_enroll_3000_3500,tot_enroll_3500_4000,tot_enroll_4000_4500,avg_class_0_5,\\\n",
    "#                   avg_class_5_10,avg_class_10_15,avg_class_15_20,avg_class_20_25,avg_class_25_30,avg_class_30_35]\n",
    "\n",
    "columns_to_add = [ap_test_taken_1_33_below,ap_test_taken_1_33_66,ap_test_taken_1_66_above,ap_test_taken_2_33_below,\\\n",
    "                  ap_test_taken_2_33_66,ap_test_taken_2_66_above,ap_test_taken_3_33_below,ap_test_taken_3_33_66,\\\n",
    "                  ap_test_taken_3_66_above,ap_test_taken_4_33_below,ap_test_taken_4_33_66,ap_test_taken_4_66_above,\\\n",
    "                  ap_test_taken_5_plus_33_below,ap_test_taken_5_plus_33_66,ap_test_taken_5_plus_66_above,\\\n",
    "                  not_eng_33_below,not_eng_33_66,not_eng_66_above,tot_enroll_0_500,tot_enroll_500_1000,\\\n",
    "                  tot_enroll_1000_1500,tot_enroll_1500_2000,tot_enroll_2000_2500,tot_enroll_2500_3000,\\\n",
    "                  tot_enroll_3000_3500,tot_enroll_3500_4000,tot_enroll_4000_4500,avg_class_0_5,avg_class_5_10,\\\n",
    "                  avg_class_10_15,avg_class_15_20,avg_class_20_25,avg_class_25_30,avg_class_30_35,SAT_taken_0_100,\\\n",
    "                  SAT_taken_100_200,SAT_taken_200_300,SAT_taken_300_400,SAT_taken_400_500,SAT_taken_500_600,\\\n",
    "                  SAT_taken_600_700,AP_taken_0_100,AP_taken_100_200,AP_taken_200_300,AP_taken_300_400,\\\n",
    "                  AP_taken_400_500,AP_taken_500_600,AP_taken_600_700,AP_taken_700_800,AP_taken_800_900,\\\n",
    "                  AP_taken_900_1000,AP_taken_1000_1100,Tot_num_classes_0_250,Tot_num_classes_250_500,\\\n",
    "                  Tot_num_classes_500_750,Tot_num_classes_750_1000,Tot_num_classes_1000_1250,Tot_num_classes_1250_1500,\\\n",
    "                  Tot_num_classes_1500_1750,Tot_num_classes_1750_2000,Tot_num_classes_2000_2250]\n",
    "\n",
    "# new_col_names = ['Disability Percent 0-33','Disability Percent 33-66','Disability Percent 66-100',\\\n",
    "#                  'High Needs Percent 0-33','High Needs Percent 33-66','High Needs Percent 66-100',\\\n",
    "#                  'Econ Disadvantage Percent 0-33','Econ Disadvantage Percent 33-66','Econ Disadvantage 66-100',\\\n",
    "#                  'African American 0-33','African American Percent 33-66','African American Percent 66-100',\\\n",
    "#                  'Asian Percent 0-33','Asian Percent 33-66','Asian Percent 66-100','Hispanic Percent 0-33',\\\n",
    "#                  'Hispanic Percent 33-66','Hispanic Percent 66-100','White Percent 0-33','White Percent 33-66',\\\n",
    "#                  'White Percent 66-100','Native Percent 0-33','Native Percent 33-66','Native Percent 66-100',\\\n",
    "#                  'Pacific Percent 0-33','Pacific Percent 33-66','Pacific Percent 66-100','Multi-Race Percent 0-33',\\\n",
    "#                  'Multi-Race Percent 33-66','Multi-Race Percent 66-100','1 AP Test Percent 0-33',\\\n",
    "#                  '1 AP Test Percent 33-66','1 AP Test Percent 66-100','2 AP Test Percent 0-33',\\\n",
    "#                  '2 AP Test Percent 33-66','2 AP Test Percent 66-100','3 AP Test Percent 0-33',\\\n",
    "#                  '3 AP Test Percent 33-66','3 AP Test Percent 66-100','4 AP Test Percent 0-33',\\\n",
    "#                  '4 AP Test Percent 33-66','4 AP Test Percent 66-100','5+ AP Test Percent 0-33',\\\n",
    "#                  '5+ AP Test Percent 33-66','5+ AP Test Percent 66-100','First Lang Not Eng Percent 0-33',\\\n",
    "#                  'First Lang Not Eng Percent 33-66','First Lang Not Eng Percent 66-100','12th Enroll 0-100',\\\n",
    "#                  '12th Enroll 100-200','12th Enroll 200-300','12th Enroll 300-400','12th Enroll 400-500',\\\n",
    "#                  '12th Enroll 500-600','12th Enroll 600-700','12th Enroll 700-800','12th Enroll 800-900',\\\n",
    "#                  '12th Enroll 900-1000','Total Enroll 0-500','Total Enroll 500-1000','Total Enroll 1000-1500',\\\n",
    "#                  'Total Enroll 1500-2000','Total Enroll 2000-2500','Total Enroll 2500-3000','Total Enroll 3000-3500',\\\n",
    "#                  'Total Enroll 3500-4000','Total Enroll 4000-4500', 'Avg Class Size 0-5','Avg Class Size 5-10',\\\n",
    "#                  'Avg Class Size 10-15','Avg Class Size 15-20','Avg Class Size 20-25','Avg Class Size 25-30',\\\n",
    "#                  'Avg Class Size 30-35']\n",
    "\n",
    "new_col_names = ['1 AP Test Percent 33-66','1 AP Test Percent 66-100','2 AP Test Percent 0-33',\\\n",
    "                 '2 AP Test Percent 33-66','2 AP Test Percent 66-100','3 AP Test Percent 0-33',\\\n",
    "                 '3 AP Test Percent 33-66','3 AP Test Percent 66-100','4 AP Test Percent 0-33',\\\n",
    "                 '4 AP Test Percent 33-66','4 AP Test Percent 66-100','5+ AP Test Percent 0-33',\\\n",
    "                 '5+ AP Test Percent 33-66','5+ AP Test Percent 66-100','First Lang Not Eng Percent 0-33',\\\n",
    "                 'First Lang Not Eng Percent 33-66','First Lang Not Eng Percent 66-100','Total Enroll 0-500',\\\n",
    "                 'Total Enroll 500-1000','Total Enroll 1000-1500','Total Enroll 1500-2000','Total Enroll 2000-2500',\\\n",
    "                 'Total Enroll 2500-3000','Total Enroll 3000-3500','Total Enroll 3500-4000','Total Enroll 4000-4500',\\\n",
    "                 'Avg Class Size 0-5','Avg Class Size 5-10','Avg Class Size 10-15','Avg Class Size 15-20',\\\n",
    "                 'Avg Class Size 20-25','Avg Class Size 25-30','Avg Class Size 30-35','SAT Taken 0-100',\\\n",
    "                 'SAT Taken 100-200','SAT Taken 200-300','SAT Taken 300-400','SAT Taken 400-500','SAT Taken 500-600',\\\n",
    "                 'SAT Taken 600-700', 'AP Test Takers 0-100','AP Test Takers 100-200','AP Test Takers 200-300',\\\n",
    "                 'AP Test Takers 300-400','AP Test Takers 400-500','AP Test Takers 500-600',\\\n",
    "                 'AP Test Takers 600-700','AP Test Takers 700-800','AP Test Takers 800-900',\\\n",
    "                 'AP Test Takers 900-1000','AP Test Takers 1000-1100','Total Num Classes 0-250',\\\n",
    "                 'Total Num Classes 250-500','Total Num Classes 500-750','Total Num Classes 750-1000',\\\n",
    "                 'Total Num Classes 1000-1250','Total Num Classes 1250-1500',\\\n",
    "                 'Total Num Classes 1500-1750','Total Num Classes 1750-2000','Total Num Classes 2000-2250']\n",
    "\n",
    "for i in range(len(new_col_names)):\n",
    "    clean_imp_cols[new_col_names[i]] = pd.DataFrame(columns_to_add[i], index=clean_imp_cols.index) "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Remove non-binary/unused columns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 209,
   "metadata": {},
   "outputs": [],
   "source": [
    "clean_imp_cols = clean_imp_cols.drop(columns=['Total # of Classes', 'TOTAL_Enrollment',\\\n",
    "                                              'Percent First Language Not English','Average Class Size',\\\n",
    "                                              'Percent Attending College','AP_Test Takers','AP_One Test',\\\n",
    "                                              'AP_Two Tests', 'AP_Three Tests','AP_Four Tests',\\\n",
    "                                              'AP_Five or More Tests','SAT_Tests Taken']);"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 210,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['1 AP Test Percent 33-66',\n",
       " '1 AP Test Percent 66-100',\n",
       " '2 AP Test Percent 0-33',\n",
       " '2 AP Test Percent 33-66',\n",
       " '2 AP Test Percent 66-100',\n",
       " '3 AP Test Percent 0-33',\n",
       " '3 AP Test Percent 33-66',\n",
       " '3 AP Test Percent 66-100',\n",
       " '4 AP Test Percent 0-33',\n",
       " '4 AP Test Percent 33-66',\n",
       " '4 AP Test Percent 66-100',\n",
       " '5+ AP Test Percent 0-33',\n",
       " '5+ AP Test Percent 33-66',\n",
       " '5+ AP Test Percent 66-100',\n",
       " 'First Lang Not Eng Percent 0-33',\n",
       " 'First Lang Not Eng Percent 33-66',\n",
       " 'First Lang Not Eng Percent 66-100',\n",
       " 'Total Enroll 0-500',\n",
       " 'Total Enroll 500-1000',\n",
       " 'Total Enroll 1000-1500',\n",
       " 'Total Enroll 1500-2000',\n",
       " 'Total Enroll 2000-2500',\n",
       " 'Total Enroll 2500-3000',\n",
       " 'Total Enroll 3000-3500',\n",
       " 'Total Enroll 3500-4000',\n",
       " 'Total Enroll 4000-4500',\n",
       " 'Avg Class Size 0-5',\n",
       " 'Avg Class Size 5-10',\n",
       " 'Avg Class Size 10-15',\n",
       " 'Avg Class Size 15-20',\n",
       " 'Avg Class Size 20-25',\n",
       " 'Avg Class Size 25-30',\n",
       " 'Avg Class Size 30-35',\n",
       " 'SAT Taken 0-100',\n",
       " 'SAT Taken 100-200',\n",
       " 'SAT Taken 200-300',\n",
       " 'SAT Taken 300-400',\n",
       " 'SAT Taken 400-500',\n",
       " 'SAT Taken 500-600',\n",
       " 'SAT Taken 600-700',\n",
       " 'AP Test Takers 0-100',\n",
       " 'AP Test Takers 100-200',\n",
       " 'AP Test Takers 200-300',\n",
       " 'AP Test Takers 300-400',\n",
       " 'AP Test Takers 400-500',\n",
       " 'AP Test Takers 500-600',\n",
       " 'AP Test Takers 600-700',\n",
       " 'AP Test Takers 700-800',\n",
       " 'AP Test Takers 800-900',\n",
       " 'AP Test Takers 900-1000',\n",
       " 'AP Test Takers 1000-1100',\n",
       " 'Total Num Classes 0-250',\n",
       " 'Total Num Classes 250-500',\n",
       " 'Total Num Classes 500-750',\n",
       " 'Total Num Classes 750-1000',\n",
       " 'Total Num Classes 1000-1250',\n",
       " 'Total Num Classes 1250-1500',\n",
       " 'Total Num Classes 1500-1750',\n",
       " 'Total Num Classes 1750-2000',\n",
       " 'Total Num Classes 2000-2250']"
      ]
     },
     "execution_count": 210,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "clean_imp_cols.columns.tolist()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Add Outcome column to end of dataframe"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 211,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "52\n",
      "60\n",
      "[63, 79, 153, 118, 99, 78, 208, 73, 14, 288, 6, 1, 293, 2, 0, 246, 42, 7, 65, 114, 73, 29, 11, 1, 1, 0, 1, 0, 1, 106, 172, 12, 3, 1, 106, 97, 62, 23, 6, 0, 1, 100, 93, 60, 26, 13, 1, 0, 0, 1, 0, 1, 52, 117, 76, 33, 11, 3, 2, 0]\n"
     ]
    }
   ],
   "source": [
    "num_non_zeros = [];\n",
    "for i in range(len(clean_imp_cols.columns)):\n",
    "    num_non_zeros.append(np.count_nonzero(np.array(clean_imp_cols)[:,i])) \n",
    "    \n",
    "print(np.count_nonzero(np.array(num_non_zeros)))\n",
    "print(len(num_non_zeros))\n",
    "print(num_non_zeros)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 212,
   "metadata": {},
   "outputs": [],
   "source": [
    "clean_imp_cols['Outcome'] = pd.DataFrame(outcome_bin, index=clean_imp_cols.index)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 245,
   "metadata": {},
   "outputs": [],
   "source": [
    "clean_imp_cols = np.array(clean_imp_cols)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 246,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(295, 61)\n"
     ]
    }
   ],
   "source": [
    "print(np.shape(clean_imp_cols));"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 247,
   "metadata": {},
   "outputs": [],
   "source": [
    "pos_cases = clean_imp_cols[clean_imp_cols[:,60]==1]\n",
    "neg_cases = clean_imp_cols[clean_imp_cols[:,60]==-1]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 248,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[1 0 0 ... 0 0 1]\n",
      " [0 0 1 ... 0 0 1]\n",
      " [0 0 1 ... 0 0 1]\n",
      " ...\n",
      " [0 0 1 ... 0 0 1]\n",
      " [0 1 0 ... 0 0 1]\n",
      " [0 0 1 ... 0 0 1]]\n"
     ]
    }
   ],
   "source": [
    "print(pos_cases)\n",
    "index = [];\n",
    "\n",
    "for i in range(1,len(pos_cases)+1):\n",
    "    index.append(int(i))\n",
    "    \n",
    "pos_cases = np.concatenate((np.array(index) [:,np.newaxis],pos_cases), axis = 1) "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 249,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[  1   1   0 ...   0   0   1]\n",
      " [  2   0   0 ...   0   0   1]\n",
      " [  3   0   0 ...   0   0   1]\n",
      " ...\n",
      " [253   0   0 ...   0   0   1]\n",
      " [254   0   1 ...   0   0   1]\n",
      " [255   0   0 ...   0   0   1]]\n"
     ]
    }
   ],
   "source": [
    "print(pos_cases)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 250,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[ 1  0  0 ...  0  0 -1]\n",
      " [ 0  0  1 ...  0  0 -1]\n",
      " [ 0  1  0 ...  0  0 -1]\n",
      " ...\n",
      " [ 1  0  0 ...  0  0 -1]\n",
      " [ 0  0  1 ...  0  0 -1]\n",
      " [ 0  0  1 ...  0  0 -1]]\n"
     ]
    }
   ],
   "source": [
    "print(neg_cases)\n",
    "index = [];\n",
    "\n",
    "for i in range(1,len(neg_cases)+1):\n",
    "    index.append(int(i))\n",
    "    \n",
    "neg_cases = np.concatenate((np.array(index) [:,np.newaxis],neg_cases), axis = 1) "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 251,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[ 1  1  0 ...  0  0 -1]\n",
      " [ 2  0  0 ...  0  0 -1]\n",
      " [ 3  0  1 ...  0  0 -1]\n",
      " ...\n",
      " [38  1  0 ...  0  0 -1]\n",
      " [39  0  0 ...  0  0 -1]\n",
      " [40  0  0 ...  0  0 -1]]\n"
     ]
    }
   ],
   "source": [
    "print(neg_cases)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Save cleaned data to csv file to be used in AMPL"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 252,
   "metadata": {},
   "outputs": [],
   "source": [
    "# clean_imp_cols.to_csv('clean_school_data.csv', index=False)\n",
    "savetxt('clean_school_data.csv',clean_imp_cols,delimiter = ',')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 253,
   "metadata": {},
   "outputs": [],
   "source": [
    "# pos_cases.to_csv('positive_cases.csv', index=False)\n",
    "savetxt('positive_cases.csv',pos_cases,delimiter = ',')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 254,
   "metadata": {},
   "outputs": [],
   "source": [
    "# neg_cases.to_csv('negative_cases.csv', index=False)\n",
    "savetxt('negative_cases.csv',neg_cases,delimiter = ',')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
